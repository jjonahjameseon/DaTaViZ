import requests
import pandas as pd
import random
from datetime import datetime, timedelta

def generate_realistic_data():
    """G√©n√®re des donn√©es simul√©es r√©alistes pour les op√©rateurs t√©l√©coms alg√©riens"""
    companies = ['Ooredoo', 'Djezzy', 'Mobilis']

    # Posts r√©alistes
    post_contents = [
        "üåê Nouvelle offre 4G+ avec 50% de data en plus! Profitez-en maintenant!",
        "üîß Maintenance r√©seau pr√©vue cette nuit de 00h √† 04h. D√©sol√©s pour la g√™ne occasionn√©e.",
        "üìû Bonjour! Notre service client est disponible 24h/24 pour vous aider.",
        "üéâ Offre sp√©ciale Ramadan! B√©n√©ficiez de forfaits exceptionnels!",
        "‚ö†Ô∏è Attention! Des arnaqueurs se font passer pour nos agents. Ne communiquez jamais vos codes!",
        "üì∂ Am√©lioration du r√©seau dans la r√©gion d'Alger. Vos retours sont les bienvenus!",
        "üí° Astuce: Activez la Wi-Fi Calling pour des appels plus clairs!",
        "üéÅ Gagnez des forfaits gratuits en participant √† notre concours!",
        "üîî Mise √† jour: R√©solution des probl√®mes de connexion signal√©s hier.",
        "üì≤ T√©l√©chargez notre nouvelle application My Ooredoo/Djezzy/Mobilis!"
    ]

    # Commentaires r√©alistes
    positive_comments = [
        "Excellent service! R√©seau stable et d√©bit correct üëç",
        "Je suis satisfait de la qualit√© du service, bon travail!",
        "Service client tr√®s professionnel, probl√®me r√©solu en 10min",
        "ŸÖŸÖÿ™ÿßÿ≤! ÿßŸÑÿÆÿØŸÖÿ© ÿ¨ŸäÿØÿ© ŸàÿßŸÑÿ¥ÿ®ŸÉÿ© ŸÖÿ≥ÿ™ŸÇÿ±ÿ©",
        "ÿ¥ŸÉÿ±ÿß ÿπŸÑŸâ ÿßŸÑÿ™ÿ≠ÿ≥ŸäŸÜÿßÿ™ ŸÅŸä ÿßŸÑÿ¥ÿ®ŸÉÿ©",
        "Les nouvelles offres sont int√©ressantes, bon rapport qualit√©-prix"
    ]

    negative_comments = [
        "R√©seau tr√®s lent depuis 3 jours, inacceptable pour le prix pay√©!",
        "Service client injoignable, j'attends depuis 30 minutes üò†",
        "Facturation excessive, on me facture des services non souscrits",
        "ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿ®ÿ∑Ÿäÿ° ÿ¨ÿØÿßÿå ŸÑÿß ÿßÿ≥ÿ™ÿ∑Ÿäÿπ ÿßŸÑÿπŸÖŸÑ",
        "ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ° ÿ≥Ÿäÿ¶ÿ©ÿå ŸÑÿß Ÿäÿ±ÿØŸàŸÜ ÿπŸÑŸâ ÿßŸÑŸáÿßÿ™ŸÅ",
        "Pas de signal dans mon immeuble, quand est-ce que √ßa va √™tre r√©par√©?"
    ]

    neutral_comments = [
        "Quelles sont les zones couvertes par la 4G+ dans la wilaya de Blida?",
        "Comment souscrire √† l'offre Ramadan?",
        "ŸÖÿß ŸáŸä ÿ£ŸàŸÇÿßÿ™ ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°ÿü",
        "ŸÉŸäŸÅ ÿ£ÿ¥ÿ™ÿ±ŸÉ ŸÅŸä ÿßŸÑÿπÿ±ÿ∂ ÿßŸÑÿ¨ÿØŸäÿØÿü",
        "Est-ce que les anciens clients peuvent b√©n√©ficier des nouvelles promotions?"
    ]

    # G√©n√©ration des posts
    posts_data = []
    for i in range(1, 101):
        company = random.choice(companies)
        post_content = random.choice(post_contents)

        # Adapter le contenu selon l'op√©rateur
        if company == 'Ooredoo':
            post_content = post_content.replace('My Ooredoo/Djezzy/Mobilis', 'My Ooredoo')
        elif company == 'Djezzy':
            post_content = post_content.replace('My Ooredoo/Djezzy/Mobilis', 'My Djezzy')
        else:
            post_content = post_content.replace('My Ooredoo/Djezzy/Mobilis', 'My Mobilis')

        post = {
            'ID': f'POST_{company[0]}_{i:03d}',
            'Contents': post_content,
            'Lien_Post': f'https://facebook.com/{company.lower()}algerie/posts/{i}',
            'Reactions_Like': random.randint(100, 2000),
            'Reactions_Love': random.randint(50, 500),
            'Reactions_Care': random.randint(20, 200),
            'Reactions_Wow': random.randint(30, 400),
            'Reactions_Sad': random.randint(10, 150),
            'Reactions_Angry': random.randint(5, 100),
            'Reactions_Haha': random.randint(40, 300),
            'Company': company,
            'Date': (datetime.now() - timedelta(days=random.randint(0, 90))).strftime('%Y-%m-%d %H:%M:%S')
        }
        posts_data.append(post)

    # G√©n√©ration des commentaires
    comments_data = []
    for post in posts_data:
        num_comments = random.randint(5, 25)

        for j in range(num_comments):
            # Distribution r√©aliste des sentiments
            sentiment = random.choices(
                ['Positif', 'N√©gatif', 'Neutre'],
                weights=[0.30, 0.45, 0.25]
            )[0]

            # S√©lection du commentaire selon le sentiment
            if sentiment == 'Positif':
                comment_text = random.choice(positive_comments)
            elif sentiment == 'N√©gatif':
                comment_text = random.choice(negative_comments)
            else:
                comment_text = random.choice(neutral_comments)

            comment = {
                'ID_Post': post['ID'],
                'User_Name': f'User_{random.randint(1000, 9999)}',
                'Comments': comment_text,
                'Sentiments': sentiment,
                'Date_Comment': (datetime.strptime(post['Date'], '%Y-%m-%d %H:%M:%S') +
                               timedelta(hours=random.randint(1, 48))).strftime('%Y-%m-%d %H:%M:%S')
            }
            comments_data.append(comment)

    return pd.DataFrame(posts_data), pd.DataFrame(comments_data)

def get_facebook_pages_data(access_token, page_ids):
    """
    R√©cup√®re les donn√©es via l'API Facebook officielle
    N√©cessite un token d'acc√®s approuv√©
    """
    base_url = "https://graph.facebook.com/v19.0/"

    all_posts_data = []
    all_comments_data = []

    for page_id in page_ids:
        print(f"R√©cup√©ration des donn√©es pour {page_id}...")

        # R√©cup√©rer les posts de la page
        url = f"{base_url}{page_id}/posts"
        params = {
            'access_token': access_token,
            'fields': 'id,message,created_time,likes.summary(true),comments.summary(true),shares',
            'limit': 100
        }

        try:
            response = requests.get(url, params=params)
            if response.status_code == 200:
                data = response.json()
                posts = data.get('data', [])

                for post in posts:
                    # Donn√©es du post
                    post_data = {
                        'ID': post.get('id', ''),
                        'Contents': post.get('message', ''),
                        'Lien_Post': f"https://facebook.com/{post.get('id', '').replace('_', '/posts/')}",
                        'Reactions_Like': post.get('likes', {}).get('summary', {}).get('total_count', 0),
                        'Company': get_company_name(page_id),
                        'Date': post.get('created_time', '')
                    }
                    all_posts_data.append(post_data)

                    # R√©cup√©rer les commentaires du post
                    comments_url = f"{base_url}{post['id']}/comments"
                    comments_params = {
                        'access_token': access_token,
                        'fields': 'id,message,from,created_time',
                        'limit': 100
                    }

                    try:
                        comments_response = requests.get(comments_url, params=comments_params)
                        if comments_response.status_code == 200:
                            comments_data = comments_response.json().get('data', [])

                            for comment in comments_data:
                                comment_data = {
                                    'ID_Post': post.get('id', ''),
                                    'User_Name': comment.get('from', {}).get('name', ''),
                                    'Comments': comment.get('message', ''),
                                    'Date_Comment': comment.get('created_time', ''),
                                    'Sentiments': 'Neutre'  # √Ä classifier plus tard
                                }
                                all_comments_data.append(comment_data)

                        time.sleep(1)  # Respect rate limits

                    except Exception as e:
                        print(f"Erreur commentaires pour {post.get('id')}: {e}")

            else:
                print(f" Erreur API pour {page_id}: {response.status_code} - {response.text}")

        except Exception as e:
            print(f"Erreur g√©n√©rale pour {page_id}: {e}")

        time.sleep(2)  # Pause entre les pages

    return all_posts_data, all_comments_data

def get_company_name(page_id):
    """Retourne le nom de l'entreprise bas√© sur l'ID de la page"""
    mapping = {
        'ooredoo.algerie': 'Ooredoo',
        'DjezzyOfficial': 'Djezzy',
        'Mobilis.Algerie': 'Mobilis'
    }
    return mapping.get(page_id, page_id)

def classify_sentiment(comment_text):
    """
    Classification basique des sentiments
    """
    if not isinstance(comment_text, str):
        return 'Neutre'

    text_lower = comment_text.lower()

    positive_words = ['bon', 'excellent', 'super', 'g√©nial', 'bravo', 'merci', 'parfait', 'satisfait', 'bon travail', 'ŸÖŸÖÿ™ÿßÿ≤', 'ÿ¥ŸÉÿ±ÿß']
    negative_words = ['mauvais', 'nul', 'horrible', 'probl√®me', 'erreur', 'bug', 'lent', 'cher', 'arnaque', 'ÿ®ÿ∑Ÿäÿ°', 'ÿ≥Ÿäÿ¶ÿ©']

    positive_count = sum(1 for word in positive_words if word in text_lower)
    negative_count = sum(1 for word in negative_words if word in text_lower)

    if positive_count > negative_count:
        return 'Positif'
    elif negative_count > positive_count:
        return 'N√©gatif'
    else:
        return 'Neutre'

# Configuration
page_ids = ['ooredoo.algerie', 'DjezzyOfficial', 'Mobilis.Algerie']
access_token = "EAAQgB8KhXtkBQIrm89OZCPH9ZAkmCUtm77jJ4bJhTUFQHBCZB8694ZALNX2NKoZAKxTDnbiHhSZCdDuYZC9AZBZBR1AMA5MHyER8hSBFqX61ZCxylosbl4o4A0uoI93UHs8PZCj3tcWAiDTDgxirFi6s3SOXAb2wzjzUoKmWNpLzkyOFZBUaDbs3ZCkLgP4ZBIFdZAXii4w8AZDZD"
USE_SIMULATED_DATA = True

# Programme principal
print(" D√©marrage de la g√©n√©ration des datasets...")

if not USE_SIMULATED_DATA and access_token != "VOTRE_TOKEN_ICI":
    print(" Tentative de connexion √† l'API Facebook...")
    posts_data, comments_data = get_facebook_pages_data(access_token, page_ids)

    # Sauvegarder les donn√©es r√©elles
    posts_df = pd.DataFrame(posts_data)
    comments_df = pd.DataFrame(comments_data)

else:
    print(" Utilisation des donn√©es simul√©es r√©alistes...")
    posts_df, comments_df = generate_realistic_data()

# Classifier les sentiments des commentaires
if not comments_df.empty:
    comments_df['Sentiments'] = comments_df['Comments'].apply(classify_sentiment)

# Sauvegarder les fichiers CSV
posts_df.to_csv('posts.csv', index=False, encoding='utf-8-sig')
comments_df.to_csv('comments.csv', index=False, encoding='utf-8-sig')

print("Fichiers CSV cr√©√©s avec succ√®s!")
print(f" Posts dataset: {len(posts_df)} enregistrements")
print(f"Comments dataset: {len(comments_df)} enregistrements")

# Afficher les statistiques
if not comments_df.empty:
    print("\nüìà R√©partition des sentiments:")
    sentiment_counts = comments_df['Sentiments'].value_counts()
    for sentiment, count in sentiment_counts.items():
        percentage = (count / len(comments_df)) * 100
        print(f"   {sentiment}: {count} commentaires ({percentage:.1f}%)")

print(f"\n Fichiers g√©n√©r√©s:")
print("   - facebook_posts_dataset.csv")
print("   - facebook_comments_dataset.csv")
